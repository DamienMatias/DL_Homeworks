{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of convolutions with tensorflow\n",
    "\n",
    "In this notebook, you'll be using tensorflow to build a Convolutional Neural Network (CNN).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "Both, [this notebook](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Convolution.ipynb) and this [wikipedia page](https://en.wikipedia.org/wiki/Convolution) might help you understand what is a convolution.\n",
    "\n",
    "no, if we consider two functions $f$ and $g$ taking values from $\\mathbb{Z} \\to \\mathbb{R}$ then:  \n",
    "$ (f * g)[n] = \\sum_{m = -\\infty}^{+\\infty} f[m] \\cdot g[n - m] $\n",
    "\n",
    "In our case, we consider the two vectors $x$ and $w$ :  \n",
    "$ x = (x_1, x_2, ..., x_{n-1}, x_n) $  \n",
    "$ w = (w_1, w_2) $\n",
    "\n",
    "And get :   \n",
    "$ x * w = (w_1 x_1 + w_2 x_2, w_1 x_2 + w_2 x_3, ..., w_1 x_{n-1} + w_2 x_n)$\n",
    "\n",
    "\n",
    "#### Deep learning subtility :\n",
    "    \n",
    "In most of deep learning framewoks, you'll get to chose in between three paddings:\n",
    "- **Same**: $(f*g)$ has the same shape as x (we pad the entry with zeros)\n",
    "- **valid**: $(f*g)$ has the shape of x minus the shape of w plus 1 (no padding on x)\n",
    "- **Causal**: $(f*g)(n_t)$ does not depend on any $(n_{t+1})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow\n",
    "\n",
    "\"TensorFlow is an open-source software library for dataflow programming across a range of tasks. It is a symbolic math library, and also used for machine learning applications such as neural networks.[3] It is used for both research and production at Google often replacing its closed-source predecessor, DistBelief.\" - Wikipedia\n",
    "\n",
    "We'll be using tensorflow to build the models we want to use. \n",
    "\n",
    "Here below, we build a AND gate with a very simple neural network :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00839782]\n",
      " [ 0.1499088 ]\n",
      " [ 0.1499088 ]\n",
      " [ 0.78595555]] Tensor(\"Y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define our Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,0,0,1]).reshape(-1,1)\n",
    "\n",
    "# Define the tensorflow tensors\n",
    "x = tf.placeholder(tf.float32, [None, 2], name='X')  # inputs\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='Y')  # outputs\n",
    "W = tf.Variable(tf.zeros([2, 1]), name='W')\n",
    "b = tf.Variable(tf.zeros([1,]), name='b')\n",
    "\n",
    "# Define the model\n",
    "pred = tf.nn.sigmoid(tf.matmul(x, W) + b)  # Model\n",
    "\n",
    "# Define the loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred) + (1-y) * tf.log(1-pred), reduction_indices=1))\n",
    "\n",
    "# Define the optimizer method you want to use\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Include some Tensorboard visualization\n",
    "writer_train = tf.summary.FileWriter(\"./my_model/\")\n",
    "\n",
    "\n",
    "# Start training session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer_train.add_graph(sess.graph)\n",
    "    \n",
    "    for epoch in range(1000):\n",
    "        _, c, p = sess.run([optimizer, loss, pred], feed_dict={x: X,\n",
    "                                                      y: Y})\n",
    "print(p, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the graph you just created, launch tensorbord.  \n",
    "`$tensorboard --logdirs=./` on linux (with corresponding logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Get inspiration from the preceding code to build a XOR gate\n",
    "\n",
    "Design a neural network with 2 layers.\n",
    "- layer1 has 2 neurons (sigmoid or tanh activation)\n",
    "- Layer2 has 1 neuron (it outouts the prediction)\n",
    "\n",
    "And train  it\n",
    "\n",
    "It's **mandatory** that you get a **tensorboard visualization** of your graph, try to make it look good, plz :)\n",
    "\n",
    "Here below I put a graph of the model you want to have (yet your weights won't be the same)\n",
    "![graph](https://i.stack.imgur.com/nRZ6z.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50119305]\n",
      " [ 0.49835789]\n",
      " [ 0.9979583 ]\n",
      " [ 0.00235485]] Tensor(\"Y:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "### Code here\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Define our Dataset\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,1,1,0]).reshape(-1,1)\n",
    "\n",
    "# Define the tensorflow tensors\n",
    "x = tf.placeholder(tf.float32, [None, 2], name='X')  # inputs\n",
    "y = tf.placeholder(tf.float32, [None, 1], name='Y')  # outputs\n",
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([2,]), name='b1')\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([1,]), name='b2')\n",
    "\n",
    "# Define the model\n",
    "A2 = tf.nn.tanh(tf.matmul(x, W1) + b1)  # Model\n",
    "pred = tf.nn.sigmoid(tf.matmul(A2, W2) + b2)\n",
    "\n",
    "# Define the loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred) + (1-y) * tf.log(1-pred), reduction_indices=1))\n",
    "\n",
    "# Define the optimizer method you want to use\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "# Include some Tensorboard visualization\n",
    "writer_train = tf.summary.FileWriter(\"./my_modelXOR/\")\n",
    "\n",
    "\n",
    "# Start training session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer_train.add_graph(sess.graph)\n",
    "    \n",
    "    for epoch in range(10000):\n",
    "        _, c, p = sess.run([optimizer, loss, pred], feed_dict={x: X,\n",
    "                                                      y: Y})\n",
    "    print_W1 = sess.run(tf.trainable_variables(\"W1\"))\n",
    "    print_W2 = sess.run(tf.trainable_variables(\"W2\"))\n",
    "print(p, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the weights of your model\n",
    "And give an interpretation on what they are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 [array([[-4.20842218,  4.61740065],\n",
      "       [-1.56060135, -2.81463075]], dtype=float32)]\n",
      "W2 [array([[ 4.02977324],\n",
      "       [ 4.1637516 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "### Code here\n",
    "print(\"W1\", print_W1)\n",
    "print(\"W2\", print_W2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Build a CNN to predict the MNIST digits\n",
    "You can now move to CNNs. You'll have to train a convolutional neural network to predict the digits from MNIST.\n",
    "\n",
    "You might want to reuse some pieces of code from [SNN](https://nbviewer.jupyter.org/github/marc-moreaux/Deep-Learning-classes/blob/master/notebooks/Intro_to_SNN.ipynb)\n",
    "\n",
    "Your model should have 3 layers:\n",
    "- 1st layer : 6 convolutional kernels with shape (3,3)\n",
    "- 2nd layer : 6 convolutional kernels with shape (3,3)\n",
    "- 3rd layer : Softmax layer\n",
    "\n",
    "Train your model.\n",
    "\n",
    "Explain all you do, and why, make it lovely to read, plz o:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Importation of data, instead of downloading via an external source, we use the data included in Tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.random_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0 training accuracy : 0.2 loss : 0.0461328697205\n",
      "step : 100 training accuracy : 0.9 loss : 0.00744406580925\n",
      "step : 200 training accuracy : 0.92 loss : 0.0075448256731\n",
      "step : 300 training accuracy : 0.88 loss : 0.00656681001186\n",
      "step : 400 training accuracy : 0.94 loss : 0.00524492442608\n",
      "step : 500 training accuracy : 0.88 loss : 0.00783619523048\n",
      "step : 600 training accuracy : 0.9 loss : 0.00688884556293\n",
      "step : 700 training accuracy : 0.88 loss : 0.00921800553799\n",
      "step : 800 training accuracy : 0.96 loss : 0.00392190784216\n",
      "step : 900 training accuracy : 0.98 loss : 0.00367008507252\n",
      "step : 1000 training accuracy : 0.86 loss : 0.0116500866413\n",
      "step : 1100 training accuracy : 0.86 loss : 0.0114709615707\n",
      "step : 1200 training accuracy : 0.92 loss : 0.00841698467731\n",
      "step : 1300 training accuracy : 0.98 loss : 0.00550443410873\n",
      "step : 1400 training accuracy : 0.92 loss : 0.0100123286247\n",
      "step : 1500 training accuracy : 0.92 loss : 0.0081374257803\n",
      "step : 1600 training accuracy : 0.94 loss : 0.00427935183048\n",
      "step : 1700 training accuracy : 0.94 loss : 0.00924634337425\n",
      "step : 1800 training accuracy : 0.94 loss : 0.00498230785131\n",
      "step : 1900 training accuracy : 0.9 loss : 0.00784926772118\n",
      "step : 2000 training accuracy : 0.88 loss : 0.00623625993729\n",
      "step : 2100 training accuracy : 0.9 loss : 0.00717251896858\n",
      "step : 2200 training accuracy : 1.0 loss : 0.00182185605168\n",
      "step : 2300 training accuracy : 0.88 loss : 0.0100975871086\n",
      "step : 2400 training accuracy : 0.86 loss : 0.0228860330582\n",
      "step : 2500 training accuracy : 0.92 loss : 0.00650386035442\n",
      "step : 2600 training accuracy : 0.92 loss : 0.00427766501904\n",
      "step : 2700 training accuracy : 1.0 loss : 0.00203851133585\n",
      "step : 2800 training accuracy : 0.9 loss : 0.00726583182812\n",
      "step : 2900 training accuracy : 0.9 loss : 0.0166505324841\n",
      "step : 3000 training accuracy : 0.98 loss : 0.00138915702701\n",
      "step : 3100 training accuracy : 0.94 loss : 0.00417171448469\n",
      "step : 3200 training accuracy : 0.94 loss : 0.00840837776661\n",
      "step : 3300 training accuracy : 0.92 loss : 0.00571288108826\n",
      "step : 3400 training accuracy : 0.96 loss : 0.00509732663631\n",
      "step : 3500 training accuracy : 0.96 loss : 0.0043821516633\n",
      "step : 3600 training accuracy : 0.88 loss : 0.0115207600594\n",
      "step : 3700 training accuracy : 0.96 loss : 0.00602516114712\n",
      "step : 3800 training accuracy : 0.94 loss : 0.00632453858852\n",
      "step : 3900 training accuracy : 0.96 loss : 0.00513141870499\n",
      "step : 4000 training accuracy : 0.92 loss : 0.00877080023289\n",
      "step : 4100 training accuracy : 0.9 loss : 0.0130749249458\n",
      "step : 4200 training accuracy : 0.84 loss : 0.0191534531116\n",
      "step : 4300 training accuracy : 0.94 loss : 0.00499256402254\n",
      "step : 4400 training accuracy : 0.94 loss : 0.00328910261393\n",
      "step : 4500 training accuracy : 0.96 loss : 0.00313306838274\n",
      "step : 4600 training accuracy : 1.0 loss : 0.00208960652351\n",
      "step : 4700 training accuracy : 0.92 loss : 0.00924045741558\n",
      "step : 4800 training accuracy : 0.92 loss : 0.00585426092148\n",
      "step : 4900 training accuracy : 0.94 loss : 0.00471773415804\n",
      "step : 5000 training accuracy : 0.82 loss : 0.0124147760868\n",
      "step : 5100 training accuracy : 0.88 loss : 0.00868485331535\n",
      "step : 5200 training accuracy : 0.94 loss : 0.00346428334713\n",
      "step : 5300 training accuracy : 0.96 loss : 0.00367588996887\n",
      "step : 5400 training accuracy : 0.9 loss : 0.00868011713028\n",
      "step : 5500 training accuracy : 0.96 loss : 0.00622499763966\n",
      "step : 5600 training accuracy : 0.84 loss : 0.00888000547886\n",
      "step : 5700 training accuracy : 0.96 loss : 0.00537285864353\n",
      "step : 5800 training accuracy : 0.96 loss : 0.00376362383366\n",
      "step : 5900 training accuracy : 0.94 loss : 0.00564607381821\n",
      "step : 6000 training accuracy : 0.92 loss : 0.00406757593155\n",
      "step : 6100 training accuracy : 0.9 loss : 0.00634319126606\n",
      "step : 6200 training accuracy : 0.9 loss : 0.00734779179096\n",
      "step : 6300 training accuracy : 0.9 loss : 0.00908856511116\n",
      "step : 6400 training accuracy : 0.96 loss : 0.00487755894661\n",
      "step : 6500 training accuracy : 0.9 loss : 0.00775404512882\n",
      "step : 6600 training accuracy : 0.86 loss : 0.0081541955471\n",
      "step : 6700 training accuracy : 0.9 loss : 0.00570462584496\n",
      "step : 6800 training accuracy : 0.88 loss : 0.00616726279259\n",
      "step : 6900 training accuracy : 0.94 loss : 0.00463212937117\n",
      "step : 7000 training accuracy : 0.92 loss : 0.00558374047279\n",
      "step : 7100 training accuracy : 0.9 loss : 0.011116079092\n",
      "step : 7200 training accuracy : 0.9 loss : 0.0087714868784\n",
      "step : 7300 training accuracy : 0.92 loss : 0.00585509240627\n",
      "step : 7400 training accuracy : 0.92 loss : 0.0070703971386\n",
      "step : 7500 training accuracy : 0.98 loss : 0.00250953137875\n",
      "step : 7600 training accuracy : 0.9 loss : 0.00522869110107\n",
      "step : 7700 training accuracy : 0.94 loss : 0.00232761248946\n",
      "step : 7800 training accuracy : 0.9 loss : 0.0109629011154\n",
      "step : 7900 training accuracy : 0.96 loss : 0.00324785411358\n",
      "step : 8000 training accuracy : 0.92 loss : 0.00588176250458\n",
      "step : 8100 training accuracy : 0.96 loss : 0.00212096512318\n",
      "step : 8200 training accuracy : 0.98 loss : 0.00218620479107\n",
      "step : 8300 training accuracy : 0.96 loss : 0.00468735575676\n",
      "step : 8400 training accuracy : 0.92 loss : 0.0095692139864\n",
      "step : 8500 training accuracy : 0.88 loss : 0.00881247580051\n",
      "step : 8600 training accuracy : 0.88 loss : 0.0062580114603\n",
      "step : 8700 training accuracy : 0.94 loss : 0.00365119546652\n",
      "step : 8800 training accuracy : 0.88 loss : 0.0130559909344\n",
      "step : 8900 training accuracy : 0.92 loss : 0.0072783356905\n",
      "step : 9000 training accuracy : 0.96 loss : 0.00377775877714\n",
      "step : 9100 training accuracy : 0.9 loss : 0.00657442092896\n",
      "step : 9200 training accuracy : 0.94 loss : 0.00641777932644\n",
      "step : 9300 training accuracy : 0.94 loss : 0.00492944061756\n",
      "step : 9400 training accuracy : 0.9 loss : 0.0187404870987\n",
      "step : 9500 training accuracy : 0.92 loss : 0.00559637665749\n",
      "step : 9600 training accuracy : 0.94 loss : 0.00589452147484\n",
      "step : 9700 training accuracy : 0.94 loss : 0.00622559607029\n",
      "step : 9800 training accuracy : 0.94 loss : 0.00380617856979\n",
      "step : 9900 training accuracy : 0.98 loss : 0.00246596768498\n",
      "step : 10000 training accuracy : 0.96 loss : 0.00227949276567\n",
      "step : 10100 training accuracy : 0.92 loss : 0.003539724648\n",
      "step : 10200 training accuracy : 0.96 loss : 0.00281788706779\n",
      "step : 10300 training accuracy : 0.9 loss : 0.00477078855038\n",
      "step : 10400 training accuracy : 0.94 loss : 0.00687817811966\n",
      "step : 10500 training accuracy : 0.92 loss : 0.010969247818\n",
      "step : 10600 training accuracy : 0.96 loss : 0.00305212050676\n",
      "step : 10700 training accuracy : 0.88 loss : 0.0068381100893\n",
      "step : 10800 training accuracy : 0.94 loss : 0.00372559309006\n",
      "step : 10900 training accuracy : 0.94 loss : 0.00525626242161\n",
      "step : 11000 training accuracy : 0.96 loss : 0.00352013736963\n",
      "step : 11100 training accuracy : 0.92 loss : 0.00561074852943\n",
      "step : 11200 training accuracy : 0.88 loss : 0.00698076486588\n",
      "step : 11300 training accuracy : 0.92 loss : 0.00431196123362\n",
      "step : 11400 training accuracy : 0.84 loss : 0.0154653537273\n",
      "step : 11500 training accuracy : 0.88 loss : 0.00720371484756\n",
      "step : 11600 training accuracy : 0.94 loss : 0.00417085200548\n",
      "step : 11700 training accuracy : 0.94 loss : 0.00468385457993\n",
      "step : 11800 training accuracy : 0.96 loss : 0.00388027280569\n",
      "step : 11900 training accuracy : 0.94 loss : 0.00379671782255\n",
      "step : 12000 training accuracy : 0.96 loss : 0.00302602142096\n",
      "step : 12100 training accuracy : 0.92 loss : 0.00598546564579\n",
      "step : 12200 training accuracy : 0.9 loss : 0.00889933407307\n",
      "step : 12300 training accuracy : 0.94 loss : 0.00352429568768\n",
      "step : 12400 training accuracy : 0.92 loss : 0.00908783853054\n",
      "step : 12500 training accuracy : 0.96 loss : 0.00396184355021\n",
      "step : 12600 training accuracy : 0.98 loss : 0.00323060333729\n",
      "step : 12700 training accuracy : 0.96 loss : 0.00249733656645\n",
      "step : 12800 training accuracy : 0.86 loss : 0.0102335584164\n",
      "step : 12900 training accuracy : 0.96 loss : 0.00331950187683\n",
      "step : 13000 training accuracy : 0.94 loss : 0.00540611684322\n",
      "step : 13100 training accuracy : 0.96 loss : 0.0056005269289\n",
      "step : 13200 training accuracy : 0.96 loss : 0.00274436116219\n",
      "step : 13300 training accuracy : 0.92 loss : 0.00812890172005\n",
      "step : 13400 training accuracy : 0.84 loss : 0.0277712249756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 13500 training accuracy : 0.9 loss : 0.00609301447868\n",
      "step : 13600 training accuracy : 0.88 loss : 0.00821358025074\n",
      "step : 13700 training accuracy : 0.94 loss : 0.00307634145021\n",
      "step : 13800 training accuracy : 0.92 loss : 0.00693317055702\n",
      "step : 13900 training accuracy : 0.9 loss : 0.00895529270172\n",
      "step : 14000 training accuracy : 0.94 loss : 0.00415851861238\n",
      "step : 14100 training accuracy : 0.9 loss : 0.004808421731\n",
      "step : 14200 training accuracy : 0.94 loss : 0.00363384157419\n",
      "step : 14300 training accuracy : 0.96 loss : 0.00303963065147\n",
      "step : 14400 training accuracy : 0.86 loss : 0.00863587617874\n",
      "step : 14500 training accuracy : 0.88 loss : 0.00621112048626\n",
      "step : 14600 training accuracy : 0.96 loss : 0.00376538097858\n",
      "step : 14700 training accuracy : 0.94 loss : 0.00535335242748\n",
      "step : 14800 training accuracy : 0.9 loss : 0.00940073788166\n",
      "step : 14900 training accuracy : 0.96 loss : 0.00389783322811\n",
      "step : 15000 training accuracy : 0.96 loss : 0.00342514634132\n",
      "step : 15100 training accuracy : 0.92 loss : 0.00704383909702\n",
      "step : 15200 training accuracy : 1.0 loss : 0.000752648636699\n",
      "step : 15300 training accuracy : 0.94 loss : 0.00278622239828\n",
      "step : 15400 training accuracy : 0.98 loss : 0.00119578249753\n",
      "step : 15500 training accuracy : 0.94 loss : 0.00660835266113\n",
      "step : 15600 training accuracy : 0.94 loss : 0.00275388896465\n",
      "step : 15700 training accuracy : 0.94 loss : 0.00364560842514\n",
      "step : 15800 training accuracy : 0.94 loss : 0.00822483658791\n",
      "step : 15900 training accuracy : 0.92 loss : 0.00396107584238\n",
      "step : 16000 training accuracy : 0.88 loss : 0.00719281613827\n",
      "step : 16100 training accuracy : 0.92 loss : 0.00546153783798\n",
      "step : 16200 training accuracy : 0.9 loss : 0.00904430866241\n",
      "step : 16300 training accuracy : 0.94 loss : 0.00635787427425\n",
      "step : 16400 training accuracy : 0.94 loss : 0.00722456336021\n",
      "step : 16500 training accuracy : 0.92 loss : 0.0056764292717\n",
      "step : 16600 training accuracy : 0.98 loss : 0.00331288188696\n",
      "step : 16700 training accuracy : 0.86 loss : 0.00814308404922\n",
      "step : 16800 training accuracy : 0.94 loss : 0.00587433755398\n",
      "step : 16900 training accuracy : 0.88 loss : 0.00980898618698\n",
      "step : 17000 training accuracy : 0.86 loss : 0.00641058206558\n",
      "step : 17100 training accuracy : 0.96 loss : 0.00812548816204\n",
      "step : 17200 training accuracy : 0.88 loss : 0.00660318732262\n",
      "step : 17300 training accuracy : 0.96 loss : 0.00602804243565\n",
      "step : 17400 training accuracy : 0.92 loss : 0.00937866270542\n",
      "step : 17500 training accuracy : 0.92 loss : 0.00656028151512\n",
      "step : 17600 training accuracy : 0.98 loss : 0.00214930668473\n",
      "step : 17700 training accuracy : 0.96 loss : 0.0033418148756\n",
      "step : 17800 training accuracy : 0.92 loss : 0.00677001774311\n",
      "step : 17900 training accuracy : 0.9 loss : 0.00739818811417\n",
      "step : 18000 training accuracy : 0.9 loss : 0.00907167375088\n",
      "step : 18100 training accuracy : 1.0 loss : 0.00168887346983\n",
      "step : 18200 training accuracy : 0.98 loss : 0.00192910611629\n",
      "step : 18300 training accuracy : 0.9 loss : 0.00523045599461\n",
      "step : 18400 training accuracy : 0.94 loss : 0.00459039926529\n",
      "step : 18500 training accuracy : 0.96 loss : 0.00455037802458\n",
      "step : 18600 training accuracy : 0.86 loss : 0.00715530216694\n",
      "step : 18700 training accuracy : 0.94 loss : 0.0044633936882\n",
      "step : 18800 training accuracy : 0.86 loss : 0.0106142437458\n",
      "step : 18900 training accuracy : 0.9 loss : 0.00731832265854\n",
      "step : 19000 training accuracy : 0.88 loss : 0.00501069545746\n",
      "step : 19100 training accuracy : 0.96 loss : 0.00451166063547\n",
      "step : 19200 training accuracy : 0.96 loss : 0.0019801454246\n",
      "step : 19300 training accuracy : 0.92 loss : 0.0062262159586\n",
      "step : 19400 training accuracy : 0.94 loss : 0.0100704479218\n",
      "step : 19500 training accuracy : 0.9 loss : 0.00567805886269\n",
      "step : 19600 training accuracy : 0.92 loss : 0.00633112549782\n",
      "step : 19700 training accuracy : 0.88 loss : 0.00770368278027\n",
      "step : 19800 training accuracy : 0.94 loss : 0.00447477310896\n",
      "step : 19900 training accuracy : 0.96 loss : 0.00333716094494\n",
      "test accuracy 0.9143\n"
     ]
    }
   ],
   "source": [
    "# CNN\n",
    "\n",
    "\n",
    "n_iteration = 20000\n",
    "learning_rate = 0.01\n",
    "batch_size = 50\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Initialize placeholders for input and output\n",
    "with tf.variable_scope('Placeholders') as scope:\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name='X')  # inputs\n",
    "    y = tf.placeholder(tf.float32, [None, 10], name='Y')  # outputs\n",
    "\n",
    "# Define the first layer\n",
    "with tf.variable_scope('Layer1') as scope:\n",
    "    W_conv1 = weight_variable([3, 3, 1, 6])\n",
    "    b_conv1 = bias_variable([6])\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    h_conv1 = conv2d(x_image, W_conv1) + b_conv1\n",
    "\n",
    "# Define the second layer\n",
    "with tf.variable_scope('Layer2') as scope:\n",
    "    W_conv2 = weight_variable([3, 3, 6, 6])\n",
    "    b_conv2 = bias_variable([6])\n",
    "    h_conv2 = conv2d(h_conv1, W_conv2) + b_conv2\n",
    "\n",
    "# Define the last layer\n",
    "with tf.variable_scope('Layer3') as scope:\n",
    "    # To flatten our tensor\n",
    "    h_layer3 = tf.contrib.layers.flatten(h_conv2)\n",
    "    logits = tf.layers.dense(h_layer3, 10)\n",
    "    y_conv = tf.nn.softmax(logits)\n",
    "\n",
    "# Loss\n",
    "with tf.name_scope(\"loss\"):\n",
    "    entropy = tf.losses.softmax_cross_entropy(logits=logits, onehot_labels=y)\n",
    "    loss = tf.reduce_mean(entropy)\n",
    "    \n",
    "# Optimizer\n",
    "with tf.name_scope(\"optimizer\"):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "# Get infos on accuracy\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) \n",
    "\n",
    "# To display the loss and the training accuracy in Tensorboard \n",
    "with tf.name_scope(\"summary\"):\n",
    "    tf.summary.scalar('accuracy', accuracy)\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    merge_summary = tf.summary.merge_all()\n",
    "\n",
    "# Print the logs for Tensorboard\n",
    "writer_train = tf.summary.FileWriter(\"./my_modelMNIST/\")\n",
    "\n",
    "# Run session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer_train.add_graph(sess.graph)\n",
    "    \n",
    "    for i in range(n_iteration):\n",
    "        total_loss = 0\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        _, l, summary= sess.run([optimizer, loss, merge_summary], feed_dict={x: batch[0], y: batch[1]})\n",
    "        total_loss += l\n",
    "        if i % 100 == 0:\n",
    "          train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1]})\n",
    "          print('step :', i, 'training accuracy :', train_accuracy, 'loss :', total_loss/(len(batch[0])))\n",
    "        writer_train.add_summary(summary, i)\n",
    "\n",
    "    print_W_conv1 = sess.run(W_conv1)\n",
    "    print_W_conv2 = sess.run(W_conv2)\n",
    "    print('test accuracy %g' % accuracy.eval(feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the weights of your model\n",
    "And give an interpretation on what they are doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_con1 [[[[ 0.0339084  -0.00574003  0.09405904  0.01899241  0.02146713  0.03116777]]\n",
      "\n",
      "  [[-0.01389475 -0.02093893 -0.04680197 -0.06296932 -0.0403694  -0.0970225 ]]\n",
      "\n",
      "  [[-0.02533246  0.04760861  0.00739993  0.08743949  0.01397227  0.06249897]]]\n",
      "\n",
      "\n",
      " [[[-0.05389746  0.03409469 -0.03007606  0.00130187 -0.01885582  0.0033858 ]]\n",
      "\n",
      "  [[-0.00608744 -0.02461667  0.36268565 -0.00600112  0.03524905  0.06681167]]\n",
      "\n",
      "  [[ 0.04017597 -0.02518635  0.04381526 -0.0172054  -0.02788767 -0.02161105]]]\n",
      "\n",
      "\n",
      " [[[ 0.00343605 -0.04836487 -0.04212236  0.01002444  0.0163784  -0.00384359]]\n",
      "\n",
      "  [[ 0.00457347  0.04254678  0.02201492  0.01601308 -0.06910476 -0.03424655]]\n",
      "\n",
      "  [[-0.04937457 -0.02119005 -0.03981137 -0.00272664  0.03052462  0.07071938]]]]\n",
      "W_con2 [[[[  6.12297431e-02   9.22521055e-02   1.02953715e-02   7.01771379e-02\n",
      "      7.84876756e-03   9.97670963e-02]\n",
      "   [ -4.74824458e-02   3.09986360e-02  -1.93826538e-02  -2.45424956e-02\n",
      "      7.28035420e-02   6.10135645e-02]\n",
      "   [ -2.01146472e-02   1.55939564e-01  -7.65122920e-02   5.47410399e-02\n",
      "     -3.54030952e-02  -5.08639822e-03]\n",
      "   [ -8.41142982e-02  -3.55873108e-02   1.14597656e-01   7.00418949e-02\n",
      "      2.02967487e-02  -5.32214791e-02]\n",
      "   [  6.11629635e-02  -4.85608801e-02   2.66113207e-02   4.78508137e-02\n",
      "      3.33424807e-02  -8.94956291e-02]\n",
      "   [ -6.84001222e-02  -8.71959329e-02   1.07801050e-01   1.11105636e-01\n",
      "     -5.55259883e-02  -6.84037805e-02]]\n",
      "\n",
      "  [[  1.30446572e-02   4.71226834e-02  -7.36479014e-02   1.69646591e-02\n",
      "      5.63040152e-02  -1.18184118e-02]\n",
      "   [  1.27793342e-01  -1.59197658e-01   5.48908412e-02   3.23446169e-02\n",
      "     -3.87966000e-02   3.81938703e-02]\n",
      "   [  1.04630448e-01  -3.38699967e-01   2.31441259e-01  -6.26960173e-02\n",
      "     -1.39135057e-02  -1.20418265e-01]\n",
      "   [  1.54747754e-01  -1.37745142e-01  -5.87312132e-02  -1.93075314e-01\n",
      "     -5.74979261e-02   1.15157567e-01]\n",
      "   [ -4.54765074e-02   3.58945914e-02  -6.95207193e-02  -8.30818154e-03\n",
      "      5.14610782e-02   1.24947362e-01]\n",
      "   [  3.66640501e-02  -6.20560758e-02  -4.08085734e-02  -6.27172813e-02\n",
      "     -9.78084002e-03   5.64144887e-02]]\n",
      "\n",
      "  [[ -7.86927640e-02  -1.28736282e-02  -1.82209108e-02  -4.55035195e-02\n",
      "     -7.82931298e-02  -3.51767913e-02]\n",
      "   [ -7.54814148e-02   9.99215543e-02  -9.26876143e-02  -4.22086120e-02\n",
      "      6.84235245e-02  -3.00232098e-02]\n",
      "   [ -1.49148211e-01   2.20014110e-01  -1.59735203e-01   7.36411735e-02\n",
      "      4.65486804e-03   7.14956969e-02]\n",
      "   [ -9.93095934e-02   1.81183107e-02   1.69851873e-02   1.42748095e-02\n",
      "      4.77918908e-02  -7.76839852e-02]\n",
      "   [  6.18156306e-02   4.53302683e-03   5.12472577e-02   5.86771891e-02\n",
      "     -4.61989492e-02  -5.71870953e-02]\n",
      "   [ -5.97052313e-02   2.70483103e-02   5.56363650e-02  -4.02409956e-02\n",
      "     -3.64830904e-02  -8.66967887e-02]]]\n",
      "\n",
      "\n",
      " [[[ -5.94374239e-02  -6.98660240e-02  -6.45062402e-02  -9.18310285e-02\n",
      "      1.91667527e-02   1.03189321e-02]\n",
      "   [ -1.78431086e-02  -5.08367829e-02   5.94889671e-02  -3.35767819e-03\n",
      "     -7.40432143e-02  -1.02970958e-01]\n",
      "   [ -1.01812616e-01  -1.96965426e-01   5.15669398e-03  -1.00816421e-01\n",
      "      1.07921354e-01   4.58177216e-02]\n",
      "   [ -3.78878005e-02  -3.62985879e-02   1.03165573e-02  -4.36783023e-02\n",
      "      4.83092479e-02  -9.07172859e-02]\n",
      "   [  8.16122442e-02   1.83590308e-01  -4.66229282e-02  -1.35153271e-02\n",
      "      4.97092530e-02   1.21327050e-01]\n",
      "   [  3.81851457e-02   1.26053378e-01  -8.78441557e-02  -9.23034996e-02\n",
      "     -4.59798649e-02   5.00061773e-02]]\n",
      "\n",
      "  [[ -6.29997998e-02  -1.44831166e-01   5.92281893e-02   3.48701775e-02\n",
      "     -5.63312434e-02   2.26519275e-02]\n",
      "   [  8.31668228e-02   2.36065894e-01  -4.10486711e-03  -7.82730505e-02\n",
      "     -5.18515781e-02   4.93397117e-02]\n",
      "   [  2.19895432e-04  -7.14043021e-01  -1.76154628e-01   2.43644387e-01\n",
      "     -1.60847887e-01  -1.40575886e-01]\n",
      "   [ -1.67918147e-03   1.06349185e-01   1.26657635e-01  -4.80785333e-02\n",
      "     -2.98793316e-02  -2.95750238e-02]\n",
      "   [ -4.31857221e-02  -1.77090481e-01  -2.56534684e-02   1.74833499e-02\n",
      "     -1.48621732e-02  -4.93543409e-02]\n",
      "   [ -8.20907578e-03  -8.55895057e-02   1.10821225e-01  -1.39306197e-02\n",
      "      1.90524179e-02  -8.80524367e-02]]\n",
      "\n",
      "  [[  5.29630557e-02   2.31537834e-01   5.86542040e-02   6.30832911e-02\n",
      "      6.50205612e-02   7.51798004e-02]\n",
      "   [ -4.43971194e-02  -2.51085907e-01   7.46947229e-02   1.11616053e-01\n",
      "     -3.26013193e-02   5.12178242e-02]\n",
      "   [  7.77402595e-02  -2.90485084e-01   8.65728334e-02  -1.32694766e-01\n",
      "      2.89950427e-02   3.59958336e-02]\n",
      "   [  6.96660951e-02  -7.40166381e-02   7.42028840e-03   9.55588743e-02\n",
      "     -7.66159147e-02  -1.15354015e-02]\n",
      "   [  4.32389677e-02  -3.68805863e-02  -4.09465842e-02  -9.09358915e-03\n",
      "     -5.34913577e-02   4.17857543e-02]\n",
      "   [  5.40179536e-02  -1.02008820e-01  -5.00904694e-02   1.02192000e-01\n",
      "     -1.77363586e-02   2.65411427e-03]]]\n",
      "\n",
      "\n",
      " [[[  1.69625148e-01   2.61296667e-02   1.18906051e-02   3.66632752e-02\n",
      "      8.63104612e-02  -1.00453697e-01]\n",
      "   [  2.95981988e-02  -2.02034079e-02  -3.90177332e-02   4.41970825e-02\n",
      "      6.16936646e-02   9.83599387e-03]\n",
      "   [  5.07868268e-02  -3.95101532e-02   5.69874886e-03   1.28592532e-02\n",
      "     -8.95771906e-02  -8.17707106e-02]\n",
      "   [ -4.48617944e-03  -5.47943637e-02  -2.37533469e-02   6.28948137e-02\n",
      "     -5.49430437e-02   1.15108639e-01]\n",
      "   [  5.72066978e-02  -1.28060371e-01  -3.85344476e-02   5.61627485e-02\n",
      "      2.81898417e-02  -1.02841385e-01]\n",
      "   [ -2.17973497e-02  -1.13756455e-01  -4.10746485e-02   1.39998153e-01\n",
      "      1.82099231e-02  -3.31967659e-02]]\n",
      "\n",
      "  [[ -1.20547593e-01   7.87020028e-02   1.31428763e-01   4.20217589e-03\n",
      "     -6.86980560e-02   3.46918441e-02]\n",
      "   [ -9.53487307e-02  -5.21471091e-02  -2.87937522e-02   4.81755361e-02\n",
      "      4.56376895e-02  -2.65994444e-02]\n",
      "   [  8.05094764e-02   2.19207317e-01   5.62286228e-02   4.87588942e-02\n",
      "      1.35063484e-01   1.36483327e-01]\n",
      "   [ -4.95315976e-02   4.71468940e-02   2.77002212e-02   3.82799879e-02\n",
      "      4.06545289e-02   5.05695567e-02]\n",
      "   [  3.14252526e-02   1.32769108e-01   9.87524632e-03  -2.22179368e-02\n",
      "     -3.43609303e-02   5.96552491e-02]\n",
      "   [  4.78958301e-02   2.04996035e-01   2.44194716e-02  -1.16123855e-01\n",
      "      5.05366474e-02   4.58491929e-02]]\n",
      "\n",
      "  [[ -6.06504083e-02  -1.62907213e-01  -1.31142870e-01  -3.27786878e-02\n",
      "      4.52684462e-02  -3.06974426e-02]\n",
      "   [  1.38286665e-01   9.83768031e-02   9.37464461e-03  -1.11308776e-01\n",
      "     -1.47994995e-01   1.32655427e-02]\n",
      "   [ -4.95734960e-02   1.31382737e-02  -6.64997101e-02   6.44629523e-02\n",
      "     -1.25617355e-01  -5.83681092e-03]\n",
      "   [  8.25925320e-02   2.63799564e-03   7.94298295e-03  -6.45013079e-02\n",
      "     -1.10003799e-01   1.22485133e-02]\n",
      "   [ -1.63869131e-02  -2.14313213e-02  -1.91877373e-02   3.65448259e-02\n",
      "      4.97579798e-02  -3.98608558e-02]\n",
      "   [  2.99552120e-02  -2.48602796e-02   3.90416533e-02  -1.97520144e-02\n",
      "     -8.69060110e-04  -5.06806560e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"W_con1\", print_W_conv1)\n",
    "print(\"W_con2\", print_W_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose one (tell me what you chose...)\n",
    "- Show how the gradients (show only one kernel) evolve for good and wrong prediction. (hard)\n",
    "- Initialize the kernels with values that make sense for you and show how they evolve. (easy) \n",
    "- When training is finished, show the 6+6=12 results of some convolved immages. (easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
